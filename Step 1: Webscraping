import requests
import pandas as pd
# BeautifulSoup is a Python library for pulling data out of HTML and XML files.
import bs4
from bs4 import BeautifulSoup
from itertools import count

# user defines max poems of < 46,000 to scrape from the Poetry Foundation website

max_poems = 25
poem_count = 0
page = max_poems//20 + 1

# create lists
titles_list = []
authors_list = []
links_list = []
stanzas_list = []

# scrape the browse page for poem html containers with relevant information

for page_id in range (1, page):
    r = requests.get(f'https://www.poetryfoundation.org/poems/browse#1=&page=2&sort_by=recently_added')
    soup = BeautifulSoup(r.content, 'lxml')
    poems = soup.find_all('div', class_='c-feature c-mix-feature_shrinkwrap')

    # for each poem container, find the title, author, and link to the full poem

    for item in poems:
        title = item.find('h2', class_='c-hdgSans c-hdgSans_2').text.strip()
        titles_list.append(title)

        author = item.find('span', class_='c-txt c-txt_attribution').text.strip().replace('By ', '')
        authors_list.append(author)

        link = item.find('a').get('href')
        links_list.append(link)

        # open each link and find the full poem

        r = requests.get(link)
        soup = BeautifulSoup(r.content, 'lxml')
        stanzas = soup.find('div', class_='c-feature-bd').text.strip()
        stanzas_list.append(stanzas)

        # create dataframe of all lists

        poems_df = pd.DataFrame(
            {'Titles': titles_list,
             'Authors': authors_list,
             'Links': links_list,
             'Stanzas': stanzas_list
             })

        # display the number of poems parsed after command loop

        poem_count += 1
        print(f'Poems parsed: {poem_count}')

        if poem_count == max_poems:
            poems_df.to_csv("poems_df.csv")
            exit()
